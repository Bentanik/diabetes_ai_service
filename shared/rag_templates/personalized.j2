# create_chat_command_handler.py
import os
import dotenv
import asyncio
from datetime import datetime
from typing import List, Optional, Dict
from bson import ObjectId

from core.cqrs import CommandRegistry, CommandHandler, Mediator
from core.llm import QwenLLM
from core.result import Result
from shared.messages import ChatMessage, SettingMessage
from shared.queries import GetRetrievedContextQuery
from app.database import get_collections
from app.database.enums import ChatRoleType
from app.database.models import (
    ChatHistoryModel,
    ChatSessionModel,
    SettingModel,
    UserProfileModel,
    HealthRecordModel
)
from app.dto.models import ChatHistoryModelDTO
from utils import get_logger
from ..create_chat_command import CreateChatCommand
from shared.rag_templates import render_template

dotenv.load_dotenv()


@CommandRegistry.register_handler(CreateChatCommand)
class CreateChatCommandHandler(CommandHandler):
    def __init__(self):
        super().__init__()
        self.logger = get_logger(__name__)
        self.db = get_collections()
        self.llm_client = None

        # Timeout
        self.LLM_TIMEOUT = 60
        self.TOTAL_TIMEOUT = 120

    async def get_llm_client(self) -> QwenLLM:
        if self.llm_client is None:
            self.llm_client = QwenLLM(
                model=os.getenv("QWEN_MODEL", "qwen2.5:3b-instruct"),
                base_url=os.getenv("QWEN_URL", "http://localhost:11434")
            )
        return self.llm_client

    async def _with_timeout(self, coro, timeout_seconds: int, operation_name: str):
        try:
            start_time = asyncio.get_event_loop().time()
            result = await asyncio.wait_for(coro, timeout=timeout_seconds)
            elapsed = asyncio.get_event_loop().time() - start_time
            self.logger.debug(f"{operation_name} completed in {elapsed:.2f}s")
            return result
        except asyncio.TimeoutError:
            self.logger.error(f"TIMEOUT: {operation_name} exceeded {timeout_seconds}s")
            raise asyncio.TimeoutError(f"{operation_name} timeout after {timeout_seconds}s")
        except Exception as e:
            elapsed = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"{operation_name} failed after {elapsed:.2f}s: {e}")
            raise

    async def create_session(
        self,
        user_id: str,
        title: str,
        session_id: str = None
    ) -> Optional[ChatSessionModel]:
        try:
            if user_id == "admin":
                doc = await self.db.chat_sessions.find_one({"user_id": "admin"})
                if doc:
                    return ChatSessionModel.from_dict(doc)
                session = ChatSessionModel(user_id="admin", title="Test AI")
                result = await self.db.chat_sessions.insert_one(session.to_dict())
                session._id = result.inserted_id
                return session

            if session_id:
                obj_id = ObjectId(session_id)
                doc = await self.db.chat_sessions.find_one({"_id": obj_id})
                if doc:
                    return ChatSessionModel.from_dict(doc)

            session_title = title[:100] + "..." if len(title) > 100 else title
            session = ChatSessionModel(user_id=user_id, title=session_title)
            result = await self.db.chat_sessions.insert_one(session.to_dict())
            session._id = result.inserted_id
            return session

        except Exception as e:
            self.logger.error(f"Error creating session: {e}", exc_info=True)
            return None

    async def update_session(self, session_id: str) -> bool:
        try:
            obj_id = ObjectId(session_id)
            result = await self.db.chat_sessions.update_one(
                {"_id": obj_id},
                {"$set": {"updated_at": datetime.utcnow()}}
            )
            return result.modified_count > 0
        except Exception as e:
            self.logger.error(f"Update session failed: {e}", exc_info=True)
            return False

    async def get_histories(self, session_id: str) -> List[ChatHistoryModel]:
        try:
            obj_id = ObjectId(session_id)
            cursor = self.db.chat_histories.find({"session_id": str(obj_id)}) \
                .sort("updated_at", -1).limit(20)
            docs = await cursor.to_list(length=20)
            histories = []
            for doc in docs:
                model = ChatHistoryModel.from_dict(doc)
                if isinstance(model.role, str):
                    model.role = ChatRoleType.USER if model.role.lower() == "user" else ChatRoleType.AI
                histories.append(model)
            return histories
        except Exception as e:
            self.logger.error(f"Cannot get chat history: {e}", exc_info=True)
            return []

    async def save_data(self,  ChatHistoryModel) -> bool:
        try:
            if isinstance(data.session_id, ObjectId):
                data.session_id = str(data.session_id)
            result = await self.db.chat_histories.insert_one(data.to_dict())
            return result.acknowledged
        except Exception as e:
            self.logger.error(f"Save chat history failed: {e}", exc_info=True)
            return False

    async def get_user_profile(self, user_id: str) -> Optional[UserProfileModel]:
        try:
            doc = await self.db.user_profiles.find_one({"user_id": user_id})
            return UserProfileModel.from_dict(doc) if doc else None
        except Exception as e:
            self.logger.error(f"Kh√¥ng th·ªÉ l·∫•y h·ªì s∆° ng∆∞·ªùi d√πng {user_id}: {e}")
            return None

    async def get_recent_health_records(self, user_id: str, record_type: str, top: int = 3) -> List[HealthRecordModel]:
        try:
            cursor = self.db.health_records.find({
                "user_id": user_id,
                "type": record_type
            }).sort("timestamp", -1).limit(top)
            docs = await cursor.to_list(length=top)
            return [HealthRecordModel.from_dict(doc) for doc in docs if doc]
        except Exception as e:
            self.logger.error(f"L·ªói l·∫•y ch·ªâ s·ªë: {e}")
            return []

    async def get_relevant_user_context(self, user_id: str, question: str) -> str:
        profile = await self.get_user_profile(user_id)
        if not profile or user_id == "admin":
            return ""

        parts = [
            f"B·ªánh nh√¢n: {profile.full_name} (ID: {profile.patient_id}), {profile.age} tu·ªïi, {profile.gender}, "
            f"ti·ªÉu ƒë∆∞·ªùng lo·∫°i {profile.diabetes_type}"
        ]

        if profile.complications:
            parts.append(f"Bi·∫øn ch·ª©ng: {', '.join(profile.complications)}")
        if profile.lifestyle:
            parts.append(f"L·ªëi s·ªëng: {profile.lifestyle}")
        if profile.bmi:
            parts.append(f"BMI: {profile.bmi:.1f}")

        q = question.lower()

        # Lu√¥n th√™m ch·ªâ s·ªë n·∫øu h·ªèi v·ªÅ s·ª©c kh·ªèe
        if any(kw in q for kw in ["ch·ªâ s·ªë", "g·∫ßn ƒë√¢y", "·ªïn kh√¥ng", "s·ª©c kh·ªèe", "t√¨nh tr·∫°ng"]):
            glucose_records = await self.get_recent_health_records(user_id, "BloodGlucose", top=3)
            if glucose_records:
                avg = sum(r.value for r in glucose_records) / len(glucose_records)
                latest = glucose_records[0].value
                parts.append(f"ƒê∆∞·ªùng huy·∫øt: trung b√¨nh {avg:.1f} mmol/l, g·∫ßn nh·∫•t {latest:.1f}")
            else:
                parts.append("ƒê∆∞·ªùng huy·∫øt: ch∆∞a c√≥ d·ªØ li·ªáu g·∫ßn ƒë√¢y")

            bp_records = await self.get_recent_health_records(user_id, "BloodPressure", top=2)
            if bp_records:
                sys_values = [r.value for r in bp_records if r.subtype == "t√¢m thu"]
                if sys_values:
                    avg_sys = sum(sys_values) / len(sys_values)
                    parts.append(f"Huy·∫øt √°p t√¢m thu: trung b√¨nh {avg_sys:.0f} mmHg")
            else:
                parts.append("Huy·∫øt √°p: ch∆∞a c√≥ d·ªØ li·ªáu g·∫ßn ƒë√¢y")

        return "\n".join(parts)

    async def classify_question_type(self, question: str, histories: List[ChatHistoryModel]) -> Dict[str, any]:
        llm = await self.get_llm_client()

        history_text = "\n".join([
            f"- {msg.role}: {msg.content}"
            for msg in histories[-3:]
        ]) if histories else "Kh√¥ng c√≥ l·ªãch s·ª≠."

        prompt = f"""
B·∫°n l√† h·ªá th·ªëng ph√¢n lo·∫°i c√¢u h·ªèi y t·∫ø th√¥ng minh.

H√£y ƒë·ªçc c√¢u h·ªèi v√† l·ªãch s·ª≠ tr√≤ chuy·ªán, sau ƒë√≥ tr·∫£ v·ªÅ **ch√≠nh x√°c 1 lo·∫°i** d∆∞·ªõi ƒë√¢y:

- `greeting`: L·ªùi ch√†o: "xin ch√†o", "ch√†o b·∫°n"
- `invalid`: C√¢u h·ªèi v·ªÅ t·ª± t·ª≠, b·ªè ƒëi·ªÅu tr·ªã
- `personal_info`: H·ªèi v·ªÅ ch·ªâ s·ªë, thu·ªëc, bi·∫øn ch·ª©ng c·ªßa b·∫£n th√¢n
- `trend_analysis`: C√≥ y·∫øu t·ªë th·ªùi gian: "g·∫ßn ƒë√¢y", "xu h∆∞·ªõng"
- `relational`: So s√°nh ti·ªÉu ƒë∆∞·ªùng v·ªõi b·ªánh kh√°c
- `rag_only`: Ki·∫øn th·ª©c chung, kh√¥ng li√™n quan tr·ª±c ti·∫øp

Ch·ªâ ƒë∆∞·ª£c tr·∫£ v·ªÅ **1 t·ª´ duy nh·∫•t**, kh√¥ng gi·∫£i th√≠ch, kh√¥ng vi·∫øt hoa.

---

### C√¢u h·ªèi hi·ªán t·∫°i
"{question}"

### L·ªãch s·ª≠ tr√≤ chuy·ªán (n·∫øu c√≥)
{history_text}

---

Lo·∫°i:
""".strip()

        try:
            response = await self._with_timeout(
                llm.generate(prompt=prompt, max_tokens=20, temperature=0.01),
                self.LLM_TIMEOUT,
                "Question Classification"
            )
            response = response.strip().lower()
            valid_types = ["greeting", "invalid", "personal_info", "trend_analysis", "relational", "rag_only"]
            return {"type": response} if response in valid_types else {"type": "rag_only"}
        except Exception as e:
            self.logger.error(f"LLM classification failed: {e}")
            q = question.lower()
            if any(kw in q for kw in ["ch·∫øt", "b·ªè thu·ªëc", "m·ªát qu√°"]):
                return {"type": "invalid"}
            if any(kw in q for kw in ["ch√†o", "hello"]):
                return {"type": "greeting"}
            if any(kw in q for kw in ["g·∫ßn ƒë√¢y", "xu h∆∞·ªõng"]):
                return {"type": "trend_analysis"}
            if any(kw in q for kw in ["so v·ªõi", "li√™n quan"]):
                return {"type": "relational"}
            if any(phrase in q for phrase in ["c·ªßa t√¥i", "t√¨nh tr·∫°ng t√¥i"]):
                return {"type": "personal_info"}
            return {"type": "rag_only"}

    async def _gen_rag_only_response(self, message: str, contexts: List[str], histories: List[ChatHistoryModel]) -> str:
        if not contexts:
            q = message.lower()
            if any(kw in q for kw in ["c√≥ m·∫•y lo·∫°i", "ngo√†i lo·∫°i 1 v√† 2"]):
                return (
                    "**Ngo√†i ti·ªÉu ƒë∆∞·ªùng lo·∫°i 1 v√† lo·∫°i 2**, c√≤n c√≥ m·ªôt s·ªë d·∫°ng kh√°c:\n\n"
                    "1. **Ti·ªÉu ƒë∆∞·ªùng thai k·ª≥**: X·∫£y ra trong thai k·ª≥, th∆∞·ªùng h·∫øt sau sinh.\n"
                    "2. **Ti·ªÉu ƒë∆∞·ªùng do gen (MODY)**: Hi·∫øm, di truy·ªÅn.\n\n"
                    "Tuy nhi√™n, **lo·∫°i 1 v√† lo·∫°i 2 chi·∫øm 95%** c√°c tr∆∞·ªùng h·ª£p."
                )
            return (
                "**Hi·ªán t√¥i ch∆∞a c√≥ t√†i li·ªáu** li√™n quan ƒë·∫øn c√¢u h·ªèi n√†y.\n\n"
                "N·∫øu b·∫°n c√≥ c√¢u h·ªèi v·ªÅ **ƒë∆∞·ªùng huy·∫øt, insulin, ch·∫ø ƒë·ªô ƒÉn**, t√¥i r·∫•t s·∫µn l√≤ng h·ªó tr·ª£."
            )

        try:
            with open("shared/rag_templates/system_prompt.txt", "r", encoding="utf-8") as f:
                system_prompt = f.read().strip()
        except Exception:
            system_prompt = "B·∫°n l√† chuy√™n gia y t·∫ø."

        full_context = "\n\n---\n\n".join([
            f"[T√ÄI LI·ªÜU {i+1}]\n{ctx.strip()}" for i, ctx in enumerate(contexts)
        ]) if contexts else "Kh√¥ng c√≥ t√†i li·ªáu li√™n quan."

        try:
            prompt_text = render_template(
                template_name="rag_only.j2",
                system_prompt=system_prompt,
                contexts=full_context,
                question=message,
                histories=histories
            )
        except Exception as e:
            self.logger.error(f"Template rendering failed: {e}")
            return "Xin l·ªói, hi·ªán t√¥i ch∆∞a th·ªÉ x·ª≠ l√Ω."

        llm = await self.get_llm_client()
        try:
            response = await self._with_timeout(
                llm.generate(prompt=prompt_text, max_tokens=400),
                self.LLM_TIMEOUT,
                "RAG Response Generation"
            )
            return response.strip() or "T√¥i ch∆∞a c√≥ th√¥ng tin."
        except asyncio.TimeoutError:
            return "Xin l·ªói, t√¥i ƒëang x·ª≠ l√Ω ch·∫≠m."

    async def _gen_personalized_response(self, message: str, contexts: List[str], user_context: str, user_id: str, first_time: bool, histories: List[ChatHistoryModel]) -> str:
        profile = await self.get_user_profile(user_id)
        if not profile:
            return "Kh√¥ng t√¨m th·∫•y h·ªì s∆° ng∆∞·ªùi d√πng."

        try:
            with open("shared/rag_templates/system_prompt.txt", "r", encoding="utf-8") as f:
                system_prompt = f.read().strip()
        except Exception:
            system_prompt = "B·∫°n l√† b√°c sƒ© n·ªôi ti·∫øt."

        full_context = "\n\n---\n\n".join([
            f"[T√ÄI LI·ªÜU {i+1}]\n{ctx.strip()}" for i, ctx in enumerate(contexts)
        ]) if contexts else "Kh√¥ng c√≥ t√†i li·ªáu li√™n quan."

        try:
            prompt_text = render_template(
                template_name="personalized.j2",
                system_prompt=system_prompt,
                contexts=full_context,
                user_context=user_context,
                question=message,
                full_name=profile.full_name,
                age=profile.age,
                first_time=first_time,
                histories=histories
            )
        except Exception as e:
            self.logger.error(f"Template personalized.j2 rendering failed: {e}")
            return "Xin l·ªói, hi·ªán t√¥i ch∆∞a th·ªÉ x·ª≠ l√Ω."

        llm = await self.get_llm_client()
        try:
            response = await self._with_timeout(
                llm.generate(prompt=prompt_text, max_tokens=500),
                self.LLM_TIMEOUT,
                "Personalized Response Generation"
            )
            return response.strip() or "T√¥i ch∆∞a c√≥ th√¥ng tin."
        except asyncio.TimeoutError:
            return f"Ch√†o {'b√°c' if profile.age >= 50 else 'anh/ch·ªã'} {profile.full_name}, hi·ªán t√¥i ƒëang x·ª≠ l√Ω ch·∫≠m. H√£y ti·∫øp t·ª•c theo d√µi nh√©!"
        except Exception as e:
            self.logger.error(f"LLM generation failed: {e}")
            return "Xin l·ªói, hi·ªán t√¥i ch∆∞a th·ªÉ tr·∫£ l·ªùi chi ti·∫øt."

    async def execute(self, command: CreateChatCommand) -> Result[None]:
        try:
            return await self._with_timeout(
                self._execute_internal(command),
                self.TOTAL_TIMEOUT,
                "Complete Chat Processing"
            )
        except asyncio.TimeoutError as e:
            self.logger.error(f"Total execution timeout: {e}")
            return Result.failure(
                code=ChatMessage.CHAT_CREATED_FAILED.code,
                message="Xin l·ªói, x·ª≠ l√Ω qu√° l√¢u. Vui l√≤ng th·ª≠ l·∫°i."
            )
        except Exception as e:
            self.logger.error(f"Error in _execute_internal: {e}", exc_info=True)
            return Result.failure(
                code=ChatMessage.CHAT_CREATED_FAILED.code,
                message=ChatMessage.CHAT_CREATED_FAILED.message
            )

    async def _execute_internal(self, command: CreateChatCommand) -> Result[None]:
        try:
            settings_doc = await self.db.settings.find_one({})
            if not settings_doc:
                return Result.failure(
                    code=SettingMessage.NOT_FOUND.code,
                    message=SettingMessage.NOT_FOUND.message
                )
            settings = SettingModel.from_dict(settings_doc)

            session = await self.create_session(
                user_id=command.user_id,
                title=command.content,
                session_id=command.session_id
            )
            if not session:
                return Result.failure(message="Kh√¥ng t·∫°o ƒë∆∞·ª£c session.")

            user_chat = ChatHistoryModel(
                session_id=str(session.id),
                user_id=command.user_id,
                content=command.content,
                role=ChatRoleType.USER
            )
            await self.save_data(user_chat)

            histories = await self.get_histories(session.id)
            histories.reverse()

            ai_messages = [msg for msg in histories if msg.role == ChatRoleType.AI]
            first_time = len(ai_messages) == 0
            has_previous_trend = any(
                kw in msg.content.lower()
                for kw in ["xu h∆∞·ªõng", "g·∫ßn ƒë√¢y", "ƒë√°nh gi√°", "ph√¢n t√≠ch", "thay ƒë·ªïi"]
                for msg in ai_messages
            )

            retrieval_result: Result = await Mediator.send(GetRetrievedContextQuery(query=command.content))
            self.logger.info(f"RAG Retrieval Result: success={retrieval_result.is_success}, data_count={len(retrieval_result.data) if retrieval_result.data else 0}")

            contexts = []
            if retrieval_result.is_success() and retrieval_result.
                contexts = [dto.content for dto in retrieval_result.data]

            classification = await self.classify_question_type(command.content, histories)
            question_type = classification["type"]
            self.logger.info(f"üîç Question: '{command.content}' ‚Üí Type: {question_type}")

            gen_text = ""

            if question_type == "greeting":
                profile = await self.get_user_profile(command.user_id)
                name = profile.full_name if profile else "b·∫°n"
                gen_text = f"Ch√†o {'b√°c' if profile and profile.age >= 50 else 'anh/ch·ªã'} {name}, t√¥i l√† tr·ª£ l√Ω y t·∫ø h·ªó tr·ª£ v·ªÅ b·ªánh ti·ªÉu ƒë∆∞·ªùng.\n\nCh·ªã mu·ªën bi·∫øt ƒëi·ªÅu g√¨ h√¥m nay?"

            elif question_type == "invalid":
                gen_text = await self.get_polite_response_for_invalid_question(command.content)

            elif question_type == "trend_analysis":
                gen_text = await self._gen_personalized_response(
                    message=command.content,
                    contexts=contexts,
                    user_context=await self.get_relevant_user_context(command.user_id, command.content),
                    user_id=command.user_id,
                    first_time=first_time,
                    histories=histories
                )

            elif question_type == "personal_info":
                user_context = await self.get_relevant_user_context(command.user_id, command.content)
                if "ch∆∞a c√≥ d·ªØ li·ªáu" in user_context:
                    gen_text = (
                        "Ch√†o ch·ªã, hi·ªán t√¥i ch∆∞a th·∫•y c√≥ d·ªØ li·ªáu s·ª©c kh·ªèe g·∫ßn ƒë√¢y c·ªßa ch·ªã.\n\n"
                        "Ch·ªã vui l√≤ng ƒëo v√† ghi l·∫°i ƒë∆∞·ªùng huy·∫øt, huy·∫øt √°p 1‚Äì2 l·∫ßn m·ªói ng√†y "
                        "ƒë·ªÉ t√¥i h·ªó tr·ª£ t·ªët h∆°n nh√©."
                    )
                else:
                    gen_text = await self._gen_personalized_response(
                        message=command.content,
                        contexts=contexts,
                        user_context=user_context,
                        user_id=command.user_id,
                        first_time=first_time,
                        histories=histories
                    )

            elif question_type == "relational":
                gen_text = await self._gen_rag_only_response(command.content, contexts, histories)

            else:
                gen_text = await self._gen_rag_only_response(command.content, contexts, histories)

            ai_chat = ChatHistoryModel(
                session_id=str(session.id),
                user_id=command.user_id,
                content=gen_text,
                role=ChatRoleType.AI
            )
            await self.save_data(ai_chat)
            await self.update_session(session.id)

            dto = ChatHistoryModelDTO.from_model(ai_chat)
            return Result.success(
                code=ChatMessage.CHAT_CREATED.code,
                message=ChatMessage.CHAT_CREATED.message,
                data=dto
            )

        except Exception as e:
            self.logger.error(f"Error in _execute_internal: {e}", exc_info=True)
            return Result.failure(
                code=ChatMessage.CHAT_CREATED_FAILED.code,
                message=ChatMessage.CHAT_CREATED_FAILED.message
            )