#!/usr/bin/env python3
"""Script test ƒë∆°n gi·∫£n cho LLM configuration m·ªõi."""

import os
import asyncio
import sys

# Th√™m src v√†o path
sys.path.append("src")

from core.llm_client import get_llm


async def test_current_config():
    """Test c·∫•u h√¨nh LLM hi·ªán t·∫°i."""
    print("üöÄ KI·ªÇM TRA LLM CONFIGURATION")
    print("=" * 50)

    try:
        # L·∫•y client v√† th√¥ng tin
        client = get_llm()
        info = client.get_provider_info()

        print(f"‚úÖ Base URL: {info['base_url']}")
        print(f"‚úÖ Model: {info['model']}")
        print(f"‚úÖ Temperature: {info['temperature']}")
        print(f"‚úÖ Max Tokens: {info['max_tokens']}")
        print(f"‚úÖ Has API Key: {'C√≥' if info['has_api_key'] else 'Kh√¥ng'}")

        # Test generate
        print("\nüîÑ KI·ªÇM TRA GENERATE...")
        test_prompt = "Ch√†o b·∫°n! Vi·∫øt 1 c√¢u ng·∫Øn b·∫±ng ti·∫øng Vi·ªát."
        print(f"Prompt: {test_prompt}")

        response = await client.generate(test_prompt)
        print(f"Response: {response[:100]}{'...' if len(response) > 100 else ''}")

        print("\n‚úÖ LLM ho·∫°t ƒë·ªông t·ªët!")

    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return False

    return True


def show_config_examples():
    """Hi·ªÉn th·ªã v√≠ d·ª• c·∫•u h√¨nh."""
    print("\nüìù V√ç D·ª§ C·∫§U H√åNH:")
    print("=" * 50)

    examples = {
        "OpenRouter": {
            "LLM_BASE_URL": "https://openrouter.ai/api/v1",
            "LLM_API_KEY": "sk-or-v1-xxx...",
            "LLM_MODEL": "deepseek/deepseek-r1-distill-llama-70b:free",
        },
        "Localhost (vLLM)": {
            "LLM_BASE_URL": "http://localhost:8000/v1",
            "LLM_API_KEY": "",
            "LLM_MODEL": "meta-llama/Llama-3.3-8B-Instruct",
        },
        "Ollama": {
            "LLM_BASE_URL": "http://localhost:11434/v1",
            "LLM_API_KEY": "",
            "LLM_MODEL": "llama3.2",
        },
        "OpenAI": {
            "LLM_BASE_URL": "https://api.openai.com/v1",
            "LLM_API_KEY": "sk-xxx...",
            "LLM_MODEL": "gpt-3.5-turbo",
        },
    }

    for name, config in examples.items():
        print(f"\n{name}:")
        for key, value in config.items():
            print(f"  {key}={value}")


async def main():
    """Main function."""
    # Test config hi·ªán t·∫°i
    success = await test_current_config()

    # Hi·ªÉn th·ªã examples
    show_config_examples()

    print("\nüí° C√ÅCH S·ª¨ D·ª§NG:")
    print("=" * 50)
    print("1. Thi·∫øt l·∫≠p 3 bi·∫øn m√¥i tr∆∞·ªùng: LLM_BASE_URL, LLM_API_KEY, LLM_MODEL")
    print("2. Restart ·ª©ng d·ª•ng")
    print("3. Test v·ªõi script n√†y ho·∫∑c g·ªçi API /system/llm-info")

    if not success:
        print("\n‚ö†Ô∏è  L∆∞u √Ω: C·∫ßn c·∫•u h√¨nh bi·∫øn m√¥i tr∆∞·ªùng tr∆∞·ªõc khi test!")


if __name__ == "__main__":
    asyncio.run(main())
