"""
API routes cho d·ªãch v·ª• RAG n√¢ng cao.
H·ªó tr·ª£ upload file, query, v√† qu·∫£n l√Ω knowledge base v·ªõi RAGFlow + HuggingFace.
"""

import tempfile
import os
from typing import List, Optional, Literal
from fastapi import APIRouter, UploadFile, File, HTTPException, Form, Query
from pydantic import BaseModel


# Simple response models
class QueryResponse(BaseModel):
    success: bool
    answer: str
    sources: list = []
    num_sources: int = 0
    confidence_score: float = 0.0
    retrieval_method: str = "advanced"
    processing_info: dict = {}


class DocumentUploadResponse(BaseModel):
    success: bool
    message: str
    files_processed: int = 0
    chunks_added: int = 0
    details: list = []
    advanced_features: dict = {}


class SystemInfoResponse(BaseModel):
    success: bool
    system_info: dict


class ApiResponse(BaseModel):
    success: bool
    message: str
    data: dict = {}


from rag.service import get_rag_service
from core.logging_config import get_logger

logger = get_logger(__name__)

# T·∫°o router v·ªõi prefix
router = APIRouter(prefix="/rag", tags=["RAG Vietnamese"])


# Pydantic models
class AdvancedQueryRequest(BaseModel):
    """Y√™u c·∫ßu truy v·∫•n n√¢ng cao."""

    question: str
    k: Optional[int] = None
    use_reranking: Optional[bool] = None
    include_sources: bool = True
    vietnamese_prompt: bool = True


class TextUploadRequest(BaseModel):
    """Y√™u c·∫ßu upload text."""

    text: str
    metadata: Optional[dict] = None
    preserve_structure: Optional[bool] = None


class AdvancedConfigRequest(BaseModel):
    """C·∫•u h√¨nh d·ªãch v·ª• RAG."""

    embedding_provider: str = "huggingface"
    embedding_model: str = "BAAI/bge-large-zh-v1.5"
    embedding_device: str = "cpu"
    collection_name: str = "vietnamese_kb"
    chunk_size: int = 1000
    chunk_overlap: int = 200
    use_ragflow_pdf: bool = True
    retrieval_k: int = 5


@router.post("/upload_files", response_model=DocumentUploadResponse)
async def upload_files(
    files: List[UploadFile] = File(...),
    preserve_structure: Optional[bool] = Form(
        None, description="B·∫£o to√†n c·∫•u tr√∫c t√†i li·ªáu"
    ),
):
    """
    Upload v√† x·ª≠ l√Ω nhi·ªÅu files v·ªõi RAGFlow parsing.

    H·ªó tr·ª£:
    - PDF v·ªõi RAGFlow parsing c·∫£i ti·∫øn
    - DOCX, TXT v√† c√°c ƒë·ªãnh d·∫°ng kh√°c
    - Chunking th√¥ng minh t·ªëi ∆∞u ti·∫øng Vi·ªát
    - Metadata chi ti·∫øt v·ªÅ qu√° tr√¨nh x·ª≠ l√Ω
    """
    service = get_rag_service()
    temp_files = []

    try:
        # Ki·ªÉm tra files
        if not files:
            raise HTTPException(status_code=400, detail="C·∫ßn √≠t nh·∫•t m·ªôt file")

        # L∆∞u t·∫°m c√°c files
        file_paths = []
        for file in files:
            if not file.filename:
                continue

            # T·∫°o file t·∫°m
            suffix = os.path.splitext(file.filename)[1]
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
            temp_files.append(temp_file.name)

            # Ghi n·ªôi dung
            content = await file.read()
            temp_file.write(content)
            temp_file.close()

            file_paths.append(temp_file.name)

        if not file_paths:
            raise HTTPException(status_code=400, detail="Kh√¥ng c√≥ file h·ª£p l·ªá")

        # X·ª≠ l√Ω v·ªõi d·ªãch v·ª• n√¢ng cao
        result = await service.add_documents_from_files(
            file_paths=file_paths, preserve_structure=preserve_structure
        )

        logger.info(
            f"Upload n√¢ng cao ho√†n th√†nh: {result['files_processed']} files ‚Üí {result['chunks_added']} chunks"
        )

        return DocumentUploadResponse(
            success=result["success"],
            message=result["message"],
            files_processed=result["files_processed"],
            chunks_added=result["chunks_added"],
            details=result.get("processing_details", []),
            advanced_features=result.get("advanced_features", {}),
        )

    except Exception as e:
        logger.error(f"L·ªói upload files n√¢ng cao: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω files: {str(e)}")

    finally:
        # X√≥a files t·∫°m
        for temp_file in temp_files:
            try:
                os.unlink(temp_file)
            except:
                pass


@router.post("/upload_text", response_model=DocumentUploadResponse)
async def upload_text(request: TextUploadRequest):
    """
    Upload raw text v·ªõi x·ª≠ l√Ω n√¢ng cao.

    Features:
    - Chunking th√¥ng minh cho ti·∫øng Vi·ªát
    - B·∫£o to√†n c·∫•u tr√∫c t√πy ch·ªçn
    - Metadata t√πy ch·ªânh
    """
    service = get_rag_service()

    try:
        result = await service.add_text(
            text=request.text,
            metadata=request.metadata,
            preserve_structure=request.preserve_structure,
        )

        return DocumentUploadResponse(
            success=result["success"],
            message=result["message"],
            files_processed=1,
            chunks_added=result["chunks_added"],
            advanced_features=result.get("advanced_features", {}),
        )

    except Exception as e:
        logger.error(f"L·ªói upload text: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω text: {str(e)}")


@router.post("/query_embedding_only", response_model=QueryResponse)
async def query_embedding_only(request: AdvancedQueryRequest):
    """
    üîÑ Truy v·∫•n Embedding Only (Legacy)

    Endpoint n√†y ch·ªâ s·ª≠ d·ª•ng embedding search truy·ªÅn th·ªëng.
    **Khuy·∫øn ngh·ªã:** S·ª≠ d·ª•ng `/query` (hybrid) ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët h∆°n.

    **T√¨nh hu·ªëng s·ª≠ d·ª•ng:**
    - Backward compatibility
    - So s√°nh performance v·ªõi hybrid
    - Debugging embedding behavior
    """
    service = get_rag_service()

    try:
        result = await service.query(
            question=request.question,
            k=request.k,
            use_reranking=request.use_reranking,
            include_sources=request.include_sources,
            vietnamese_prompt=request.vietnamese_prompt,
        )

        return QueryResponse(
            success=result["success"],
            answer=result["answer"],
            sources=result["sources"],
            num_sources=result["num_sources"],
            confidence_score=result.get("confidence_score", 0.0),
            retrieval_method=result.get("retrieval_method", "embedding_only_legacy"),
            processing_info=result.get("processing_info", {}),
        )

    except Exception as e:
        logger.error(f"L·ªói truy v·∫•n embedding only: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")


@router.get("/system_info", response_model=SystemInfoResponse)
async def get_system_info():
    """L·∫•y th√¥ng tin chi ti·∫øt v·ªÅ h·ªá th·ªëng RAG n√¢ng cao."""
    service = get_rag_service()

    try:
        info = service.get_system_info()
        return SystemInfoResponse(success=True, system_info=info)
    except Exception as e:
        logger.error(f"L·ªói l·∫•y system info: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")


@router.post("/configure", response_model=ApiResponse)
async def configure_service(config: AdvancedConfigRequest):
    """
    C·∫•u h√¨nh l·∫°i d·ªãch v·ª• RAG n√¢ng cao.

    Cho ph√©p thay ƒë·ªïi:
    - Model embedding
    - C·∫•u h√¨nh chunking
    - Tham s·ªë retrieval
    """
    global _rag_service

    try:
        # T·∫°o service m·ªõi v·ªõi config m·ªõi
        _rag_service = get_rag_service(
            embedding_provider=config.embedding_provider,
            embedding_model=config.embedding_model,
            embedding_device=config.embedding_device,
            collection_name=config.collection_name,
            chunk_size=config.chunk_size,
            chunk_overlap=config.chunk_overlap,
            use_ragflow_pdf=config.use_ragflow_pdf,
            retrieval_k=config.retrieval_k,
        )

        logger.info(
            f"ƒê√£ c·∫•u h√¨nh l·∫°i service v·ªõi {config.embedding_provider} embedding"
        )

        return ApiResponse(
            success=True,
            message=f"ƒê√£ c·∫•u h√¨nh l·∫°i th√†nh c√¥ng v·ªõi {config.embedding_provider} ({config.embedding_model})",
        )

    except Exception as e:
        logger.error(f"L·ªói c·∫•u h√¨nh service: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói c·∫•u h√¨nh: {str(e)}")


@router.delete("/clear", response_model=ApiResponse)
async def clear_knowledge_base():
    """X√≥a to√†n b·ªô knowledge base n√¢ng cao."""
    service = get_rag_service()

    try:
        result = await service.clear_knowledge_base()
        return ApiResponse(success=result["success"], message=result["message"])
    except Exception as e:
        logger.error(f"L·ªói x√≥a knowledge base: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")


@router.get("/health", response_model=ApiResponse)
async def health_check():
    """Ki·ªÉm tra t√¨nh tr·∫°ng d·ªãch v·ª• RAG n√¢ng cao."""
    try:
        service = get_rag_service()
        info = service.get_system_info()

        return ApiResponse(
            success=True,
            message="D·ªãch v·ª• RAG n√¢ng cao ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng",
            data={
                "service_type": info["service_type"],
                "vietnamese_optimized": info["features"]["vietnamese_optimization"],
                "ragflow_pdf": info["features"]["ragflow_pdf_parsing"],
                "embedding_provider": info["components"]["embedding_service"][
                    "provider"
                ],
            },
        )

    except Exception as e:
        logger.error(f"Health check th·∫•t b·∫°i: {e}")
        raise HTTPException(status_code=500, detail=f"Service kh√¥ng kh·∫£ d·ª•ng: {str(e)}")


@router.get("/embedding_models", response_model=ApiResponse)
async def get_available_embedding_models():
    """L·∫•y danh s√°ch models embedding ƒë∆∞·ª£c h·ªó tr·ª£."""
    from rag.embeddings import MODEL_DEFAULT_EMBEDDING

    return ApiResponse(
        success=True,
        message="Danh s√°ch models embedding ƒë∆∞·ª£c khuy·∫øn ngh·ªã cho ti·∫øng Vi·ªát",
        data={
            "vietnamese_models": MODEL_DEFAULT_EMBEDDING,
            "current_service": get_rag_service().embedding_service.get_info(),
        },
    )


@router.post("/test_embedding", response_model=ApiResponse)
async def test_embedding_performance(
    text: str = Form("ƒê√¢y l√† c√¢u test ƒë·ªÉ ki·ªÉm tra hi·ªáu su·∫•t embedding ti·∫øng Vi·ªát"),
    model_name: Optional[str] = Form(None, description="T√™n model ƒë·ªÉ test"),
):
    """Test hi·ªáu su·∫•t embedding v·ªõi text ti·∫øng Vi·ªát."""
    try:
        service = get_rag_service()

        # Test embedding v·ªõi text
        import time

        start_time = time.time()

        embedding = service.embedding_service.embed_query(text)

        end_time = time.time()
        processing_time = end_time - start_time

        return ApiResponse(
            success=True,
            message=f"Test embedding th√†nh c√¥ng trong {processing_time:.3f}s",
            data={
                "text": text,
                "embedding_dimension": len(embedding),
                "processing_time_seconds": processing_time,
                "model_info": service.embedding_service.get_info(),
                "vietnamese_optimized": True,
            },
        )

    except Exception as e:
        logger.error(f"L·ªói test embedding: {e}")
        raise HTTPException(status_code=500, detail=f"Test th·∫•t b·∫°i: {str(e)}")


# =============================================================================
# HYBRID RETRIEVAL ENDPOINTS (BM25 + Embedding)
# =============================================================================


class HybridQueryRequest(BaseModel):
    """Y√™u c·∫ßu truy v·∫•n hybrid v·ªõi BM25 + Embedding."""

    question: str
    k: Optional[int] = None
    method: Literal["hybrid", "bm25_only", "embedding_only"] = "hybrid"
    include_sources: bool = True
    vietnamese_prompt: bool = True


class HybridQueryResponse(BaseModel):
    """Ph·∫£n h·ªìi truy v·∫•n hybrid."""

    success: bool
    answer: str
    sources: list = []
    num_sources: int = 0
    confidence_score: float = 0.0
    retrieval_method: str = "hybrid"
    hybrid_info: dict = {}
    processing_info: dict = {}


class ComparisonResponse(BaseModel):
    """Ph·∫£n h·ªìi so s√°nh c√°c ph∆∞∆°ng ph√°p retrieval."""

    success: bool
    query: str
    k: int
    methods: dict
    recommendation: str
    comparison_info: dict = {}


@router.post("/query", response_model=HybridQueryResponse)
async def query_hybrid(request: HybridQueryRequest):
    """
    üéØ **RAG QUERY - ENDPOINT CH√çNH**

    **Hybrid Retrieval** (BM25 + Embedding) - Ph∆∞∆°ng ph√°p t√¨m ki·∫øm ti√™n ti·∫øn nh·∫•t:

    üî• **T·∫°i sao Hybrid t·ªët h∆°n Embedding thu·∫ßn:**
    - **T·ª´ kh√≥a k·ªπ thu·∫≠t**: BM25 t√¨m ch√≠nh x√°c "JWT", "OAuth", "API"
    - **Ng·ªØ nghƒ©a**: Embedding hi·ªÉu "b·∫£o m·∫≠t" ‚âà "security"
    - **Fusion**: K·∫øt h·ª£p ƒëi·ªÉm s·ªë t·ªëi ∆∞u cho k·∫øt qu·∫£ t·ªët nh·∫•t

    üìä **Performance:**
    - ‚úÖ +15-30% ƒë·ªô ch√≠nh x√°c vs embedding only
    - ‚úÖ T·ªët v·ªõi technical terms v√† proper nouns
    - ‚úÖ Balanced cho diverse query types

    ‚öôÔ∏è **Method Options:**
    - `"hybrid"`: BM25 + Embedding (**M·∫∂C ƒê·ªäNH - KHUY·∫æN NGH·ªä**)
    - `"bm25_only"`: Ch·ªâ t√¨m t·ª´ kh√≥a ch√≠nh x√°c
    - `"embedding_only"`: Ch·ªâ t√¨m ng·ªØ nghƒ©a (nh∆∞ endpoint c≈©)

    üí° **Tip**: ƒê·ªÉ so s√°nh v·ªõi embedding c≈©, d√πng `/query_embedding_only`
    """
    service = get_rag_service()

    try:
        result = await service.hybrid_query(
            question=request.question,
            k=request.k,
            method=request.method,
            include_sources=request.include_sources,
            vietnamese_prompt=request.vietnamese_prompt,
        )

        return HybridQueryResponse(
            success=result["success"],
            answer=result["answer"],
            sources=result["sources"],
            num_sources=result["num_sources"],
            confidence_score=result.get("confidence_score", 0.0),
            retrieval_method=result.get("retrieval_method", "hybrid"),
            hybrid_info=result.get("hybrid_info", {}),
            processing_info=result.get("processing_info", {}),
        )

    except Exception as e:
        logger.error(f"L·ªói hybrid query: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói hybrid search: {str(e)}")


@router.post("/compare_retrieval", response_model=ComparisonResponse)
async def compare_retrieval_methods(
    question: str = Form(..., description="C√¢u h·ªèi ƒë·ªÉ so s√°nh"),
    k: int = Form(5, description="S·ªë documents ƒë·ªÉ l·∫•y"),
):
    """
    üìä So s√°nh hi·ªáu su·∫•t c√°c ph∆∞∆°ng ph√°p Retrieval

    **So s√°nh gi·ªØa:**
    1. **Hybrid Fusion** - BM25 + Embedding
    2. **BM25 Only** - T√¨m t·ª´ kh√≥a ch√≠nh x√°c
    3. **Embedding Only** - T√¨m ng·ªØ nghƒ©a
    4. **Regular Embedding** - Embedding truy·ªÅn th·ªëng

    **Metrics ƒë∆∞·ª£c ƒë√°nh gi√°:**
    - S·ªë l∆∞·ª£ng documents t√¨m th·∫•y
    - ƒêi·ªÉm trung b√¨nh (confidence score)
    - Preview n·ªôi dung top 3 documents
    - Khuy·∫øn ngh·ªã ph∆∞∆°ng ph√°p t·ªët nh·∫•t

    **D√πng ƒë·ªÉ:**
    - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng retrieval cho c√¢u h·ªèi c·ª• th·ªÉ
    - Ch·ªçn ph∆∞∆°ng ph√°p t·ªëi ∆∞u cho t·ª´ng lo·∫°i query
    - Benchmarking v√† t·ªëi ∆∞u h√≥a system
    """
    service = get_rag_service()

    try:
        result = await service.compare_retrieval_methods(question, k)

        if "error" in result:
            raise HTTPException(status_code=500, detail=result["error"])

        return ComparisonResponse(
            success=True,
            query=result["query"],
            k=result["k"],
            methods=result["methods"],
            recommendation=result["comparison_info"]["recommendation"],
            comparison_info=result["comparison_info"],
        )

    except Exception as e:
        logger.error(f"L·ªói so s√°nh retrieval: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói so s√°nh: {str(e)}")


@router.get("/hybrid_stats", response_model=ApiResponse)
async def get_hybrid_retriever_stats():
    """
    üìà Th·ªëng k√™ Hybrid Retriever

    **Th√¥ng tin bao g·ªìm:**
    - C·∫•u h√¨nh BM25 (k1, b parameters)
    - Tr·ªçng s·ªë fusion (BM25 vs Embedding)
    - S·ªë l∆∞·ª£ng documents ƒë√£ indexed
    - Vocabulary size (s·ªë t·ª´ unique)
    - Th·ªëng k√™ vector store
    """
    service = get_rag_service()

    try:
        stats = service.hybrid_retriever.get_stats()

        return ApiResponse(
            success=True,
            message="Th·ªëng k√™ Hybrid Retriever",
            data={
                "hybrid_config": {
                    "retriever_type": stats["retriever_type"],
                    "bm25_weight": stats["weights"]["bm25"],
                    "embedding_weight": stats["weights"]["embedding"],
                    "bm25_initialized": stats["bm25_initialized"],
                },
                "bm25_stats": stats.get("bm25_stats", {}),
                "vectorstore_info": stats["vectorstore_info"],
                "capabilities": {
                    "keyword_search": "BM25 exact matching",
                    "semantic_search": "HuggingFace embeddings",
                    "fusion_method": "Weighted score combination",
                    "vietnamese_optimized": True,
                },
            },
        )

    except Exception as e:
        logger.error(f"L·ªói l·∫•y hybrid stats: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")


@router.post("/test_hybrid_performance", response_model=ApiResponse)
async def test_hybrid_performance(
    test_queries: List[str] = Form(
        [
            "Blockchain l√† g√¨?",
            "Machine learning algorithms",
            "C√¥ng ngh·ªá AI trong y t·∫ø",
            "Ph∆∞∆°ng ph√°p ph√¢n t√≠ch d·ªØ li·ªáu",
        ],
        description="Danh s√°ch c√¢u h·ªèi test",
    ),
    k: int = Form(3, description="S·ªë documents cho m·ªói query"),
):
    """
    üß™ Test hi·ªáu su·∫•t Hybrid Retrieval

    **Ch·∫°y benchmark tr√™n nhi·ªÅu c√¢u h·ªèi:**
    - Test c·∫£ 4 ph∆∞∆°ng ph√°p retrieval
    - ƒêo th·ªùi gian x·ª≠ l√Ω
    - So s√°nh ƒëi·ªÉm s·ªë v√† s·ªë l∆∞·ª£ng k·∫øt qu·∫£
    - T√≠nh trung b√¨nh hi·ªáu su·∫•t

    **K·∫øt qu·∫£:**
    - Performance summary cho t·ª´ng ph∆∞∆°ng ph√°p
    - Th·ªùi gian trung b√¨nh
    - Khuy·∫øn ngh·ªã optimization
    """
    service = get_rag_service()

    try:
        import time

        results = {
            "test_queries": test_queries,
            "k": k,
            "methods_performance": {},
            "summary": {},
        }

        methods = ["hybrid", "bm25_only", "embedding_only"]

        for method in methods:
            method_results = []
            total_time = 0

            for query in test_queries:
                start_time = time.time()

                query_result = await service.hybrid_query(
                    question=query,
                    k=k,
                    method=method,
                    include_sources=False,
                    vietnamese_prompt=False,
                )

                end_time = time.time()
                query_time = end_time - start_time
                total_time += query_time

                method_results.append(
                    {
                        "query": query,
                        "num_results": query_result.get("num_sources", 0),
                        "confidence": query_result.get("confidence_score", 0),
                        "time_seconds": query_time,
                    }
                )

            # T√≠nh th·ªëng k√™
            avg_results = sum(r["num_results"] for r in method_results) / len(
                method_results
            )
            avg_confidence = sum(r["confidence"] for r in method_results) / len(
                method_results
            )
            avg_time = total_time / len(test_queries)

            results["methods_performance"][method] = {
                "individual_results": method_results,
                "average_results_count": avg_results,
                "average_confidence": avg_confidence,
                "average_time_seconds": avg_time,
                "total_time_seconds": total_time,
            }

        # T√≥m t·∫Øt v√† khuy·∫øn ngh·ªã
        best_confidence = max(
            results["methods_performance"].values(),
            key=lambda x: x["average_confidence"],
        )
        fastest_method = min(
            results["methods_performance"].values(),
            key=lambda x: x["average_time_seconds"],
        )

        results["summary"] = {
            "best_confidence_method": "Ch∆∞a x√°c ƒë·ªãnh",  # C·∫ßn logic ƒë·ªÉ t√¨m method name
            "fastest_method": "Ch∆∞a x√°c ƒë·ªãnh",
            "recommendation": "Hybrid method cung c·∫•p c√¢n b·∫±ng t·ªët nh·∫•t gi·ªØa ch·∫•t l∆∞·ª£ng v√† t·ªëc ƒë·ªô",
            "optimization_tips": [
                "ƒêi·ªÅu ch·ªânh BM25 weights d·ª±a tr√™n domain c·ª• th·ªÉ",
                "Fine-tune embedding model cho d·ªØ li·ªáu ri√™ng",
                "T·ªëi ∆∞u chunk size v√† overlap cho better retrieval",
            ],
        }

        return ApiResponse(
            success=True,
            message=f"Ho√†n th√†nh test {len(test_queries)} queries v·ªõi {len(methods)} methods",
            data=results,
        )

    except Exception as e:
        logger.error(f"L·ªói test hybrid performance: {e}")
        raise HTTPException(status_code=500, detail=f"Test failed: {str(e)}")


# Search-only models (new)
class SearchOnlyRequest(BaseModel):
    """Y√™u c·∫ßu t√¨m ki·∫øm ch·ªâ retrieval - KH√îNG LLM."""

    question: str
    k: Optional[int] = None
    method: Literal["hybrid", "bm25_only", "embedding_only"] = "hybrid"
    include_sources: bool = True
    score_threshold: Optional[float] = None


class SearchOnlyResponse(BaseModel):
    """Ph·∫£n h·ªìi t√¨m ki·∫øm ch·ªâ retrieval - NHANH!"""

    success: bool
    documents: list = []  # Raw documents
    sources: list = []  # Formatted sources
    num_sources: int = 0
    search_method: str = "hybrid"
    confidence_score: float = 0.0
    query: str = ""
    k_requested: int = 5
    score_threshold: Optional[float] = None
    processing_info: dict = {}
    hybrid_stats: dict = {}


@router.post("/search", response_model=SearchOnlyResponse)
async def search_documents(request: SearchOnlyRequest):
    """
    üîç T√åM KI·∫æM DOCUMENTS - KH√îNG LLM (NHANH!)

    Ch·ªâ t√¨m ki·∫øm v√† tr·∫£ v·ªÅ documents li√™n quan, KH√îNG g·ªçi LLM ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi.

    **‚ö° Performance:**
    - Nhanh g·∫•p 20-100x so v·ªõi `/query` (v√¨ skip LLM)
    - Ph√π h·ª£p cho search, preview, debugging

    **üéØ Use Cases:**
    - T√¨m ki·∫øm nhanh documents
    - Preview n·ªôi dung tr∆∞·ªõc khi query
    - Debugging retrieval performance
    - Bulk search operations

    **Methods:**
    - `hybrid`: BM25 + Embedding (khuy·∫øn ngh·ªã)
    - `bm25_only`: Ch·ªâ keyword search
    - `embedding_only`: Ch·ªâ semantic search
    """
    service = get_rag_service()

    try:
        result = await service.search_only(
            question=request.question,
            k=request.k,
            method=request.method,
            include_sources=request.include_sources,
            score_threshold=request.score_threshold,
        )

        # Convert documents to serializable format
        documents_data = []
        for doc in result.get("documents", []):
            doc_data = {
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity_score": doc.metadata.get("similarity_score", 0.0),
            }
            documents_data.append(doc_data)

        return SearchOnlyResponse(
            success=result["success"],
            documents=documents_data,
            sources=result["sources"],
            num_sources=result["num_sources"],
            search_method=result["search_method"],
            confidence_score=result["confidence_score"],
            query=result["query"],
            k_requested=result["k_requested"],
            score_threshold=result["score_threshold"],
            processing_info=result["processing_info"],
            hybrid_stats=result["hybrid_stats"],
        )

    except Exception as e:
        logger.error(f"L·ªói search-only: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói t√¨m ki·∫øm: {str(e)}")
