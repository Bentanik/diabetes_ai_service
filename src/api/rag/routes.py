"""
RAG API routes cho knowledge base management vÃ  document processing
"""

import os
import tempfile
import time
from datetime import datetime
from typing import Dict, Any, List, Optional, Union

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query, status
from fastapi.responses import JSONResponse

from features.rag.rag_pipeline import RAGPipeline, RAGPipelineConfig
from features.rag.chunking import ChunkingConfig
from features.rag.embedding import EmbeddingConfig
from features.rag.vector_store import VectorStoreConfig, VectorStore
from features.rag.storage import document_storage
from core.logging_config import get_logger
from .models import (
    KnowledgeBaseCreate,
    KnowledgeBaseResponse,
    KnowledgeBaseList,
    FileUploadResponse,
    FileInfoModel,
)

router = APIRouter(tags=["RAG Knowledge Base"])
logger = get_logger(__name__)

SUPPORTED_EXTENSIONS = {".pdf", ".docx", ".txt", ".html", ".htm", ".csv", ".md"}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB

# Singleton pipeline
rag_pipeline: RAGPipeline | None = None


def get_rag_pipeline(collection_name: str) -> RAGPipeline:
    """Get RAG pipeline instance vá»›i collection name cá»¥ thá»ƒ."""
    global rag_pipeline
    if not rag_pipeline:
        config = RAGPipelineConfig(
            chunking_config=ChunkingConfig(),
            embedding_config=EmbeddingConfig(),
            vector_store_config=VectorStoreConfig(collection_name=collection_name),
        )
        rag_pipeline = RAGPipeline(config)
    else:
        # Update collection name náº¿u khÃ¡c
        if rag_pipeline.vector_store.config.collection_name != collection_name:
            rag_pipeline.vector_store.config.collection_name = collection_name
    return rag_pipeline


def validate_file(file: UploadFile) -> tuple[bool, str]:
    """Validate file type vÃ  size"""
    if not file.filename:
        return False, "Filename is required"

    ext = os.path.splitext(file.filename.lower())[1]
    if ext not in SUPPORTED_EXTENSIONS:
        return (
            False,
            f"Unsupported file type. Supported: {', '.join(SUPPORTED_EXTENSIONS)}",
        )

    return True, "Valid"


def format_file_info(
    file: UploadFile, size: int, storage_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Format file info cho response"""
    info = {
        "filename": file.filename,
        "file_size": size,
        "file_extension": (
            os.path.splitext(file.filename.lower())[1] if file.filename else ""
        ),
        "content_type": file.content_type or "application/octet-stream",
        "upload_time": datetime.now().isoformat(),
    }

    if storage_info:
        info.update(
            {
                "storage_path": storage_info["storage_path"],
                "storage_time": storage_info["storage_time"],
            }
        )

    return info


@router.post(
    "/knowledge-bases",
    response_model=KnowledgeBaseResponse,
    summary="ðŸ“š Táº¡o knowledge base má»›i",
    description="Táº¡o knowledge base má»›i trong vector store. Má»—i knowledge base lÃ  má»™t collection riÃªng biá»‡t.",
)
async def create_knowledge_base(kb_data: KnowledgeBaseCreate):
    """
    Táº¡o knowledge base má»›i trong vector store.

    - **name**: TÃªn cá»§a knowledge base, sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m collection name
    - **description**: MÃ´ táº£ vá» knowledge base (optional)
    - **metadata**: Metadata bá»• sung (optional)
    """
    try:
        # Khá»Ÿi táº¡o VectorStore vá»›i collection name má»›i
        config = VectorStoreConfig(collection_name=kb_data.name)
        vector_store = VectorStore(config=config)
        success = vector_store.create_collection(force_recreate=True)

        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="KhÃ´ng thá»ƒ táº¡o collection trong vector store",
            )

        info = vector_store.get_collection_info()

        # Äáº£m báº£o luÃ´n cÃ³ created_at
        created_at = info.get("created_at")
        if not created_at:
            created_at = datetime.now().isoformat()

        return KnowledgeBaseResponse(
            name=kb_data.name,
            description=kb_data.description,
            metadata=kb_data.metadata,
            collection_info=info,
            created_at=created_at,
        )

    except Exception as e:
        logger.error(f"Error creating KB: {e}")
        raise HTTPException(500, detail=f"Lá»—i khi táº¡o knowledge base: {str(e)}")


@router.get(
    "/knowledge-bases",
    response_model=KnowledgeBaseList,
    summary="ðŸ“š Láº¥y danh sÃ¡ch knowledge bases",
    description="Láº¥y danh sÃ¡ch táº¥t cáº£ knowledge bases hiá»‡n cÃ³.",
)
async def list_knowledge_bases():
    """
    Láº¥y danh sÃ¡ch táº¥t cáº£ knowledge bases.
    """
    try:
        # Khá»Ÿi táº¡o VectorStore khÃ´ng cáº§n embeddings vÃ¬ chá»‰ dÃ¹ng Ä‘á»ƒ quáº£n lÃ½ collections
        vector_store = VectorStore()
        collections = vector_store.list_collections()

        kbs = []
        for collection in collections:
            # Cáº­p nháº­t collection name vÃ  láº¥y thÃ´ng tin
            vector_store.config.collection_name = collection.name
            info = vector_store.get_collection_info()

            # Äáº£m báº£o luÃ´n cÃ³ created_at
            created_at = info.get("created_at")
            if not created_at:
                created_at = datetime.now().isoformat()

            kbs.append(
                KnowledgeBaseResponse(
                    name=collection.name,
                    description=None,  # Collection info khÃ´ng cÃ³ description
                    metadata=None,  # Collection info khÃ´ng cÃ³ metadata
                    collection_info=info,
                    created_at=created_at,
                )
            )

        return KnowledgeBaseList(
            knowledge_bases=kbs,
            total=len(kbs),
        )

    except Exception as e:
        logger.error(f"Error listing KBs: {e}")
        raise HTTPException(
            500, detail=f"Lá»—i khi láº¥y danh sÃ¡ch knowledge bases: {str(e)}"
        )


@router.delete(
    "/knowledge-bases/{name}",
    response_model=Dict[str, Any],
    summary="ðŸ—‘ï¸ XÃ³a knowledge base",
    description="XÃ³a knowledge base vÃ  táº¥t cáº£ documents trong Ä‘Ã³.",
)
async def delete_knowledge_base(name: str):
    """
    XÃ³a knowledge base.

    - **name**: TÃªn cá»§a knowledge base cáº§n xÃ³a
    """
    try:
        # Khá»Ÿi táº¡o VectorStore vá»›i collection name cáº§n xÃ³a
        config = VectorStoreConfig(collection_name=name)
        vector_store = VectorStore(config=config)
        success = vector_store.delete_collection()

        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"KhÃ´ng thá»ƒ xÃ³a knowledge base {name}",
            )

        return {
            "success": True,
            "message": f"ÄÃ£ xÃ³a knowledge base {name}",
            "time": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"Error deleting KB: {e}")
        raise HTTPException(500, detail=f"Lá»—i khi xÃ³a knowledge base: {str(e)}")


@router.post(
    "/knowledge-bases/{name}/documents",
    response_model=FileUploadResponse,
    summary="ðŸ“„ Upload document vÃ o knowledge base",
    description="Upload vÃ  process document vÃ o knowledge base cá»¥ thá»ƒ.",
)
async def upload_document(
    name: str,
    file: UploadFile = File(...),
    chunk_size: int = Form(1000),
    chunk_overlap: int = Form(200),
    metadata: Dict[str, Any] = Form({}),
):
    """
    Upload vÃ  process document vÃ o knowledge base.

    - **name**: TÃªn cá»§a knowledge base
    - **file**: File cáº§n upload
    - **chunk_size**: KÃ­ch thÆ°á»›c má»—i chunk (default: 1000)
    - **chunk_overlap**: Äá»™ overlap giá»¯a cÃ¡c chunks (default: 200)
    - **metadata**: Metadata bá»• sung cho document
    """
    start_time = time.time()
    temp_file = None

    try:
        valid, msg = validate_file(file)
        if not valid:
            raise HTTPException(400, detail=msg)

        content = await file.read()
        size = len(content)
        if size > MAX_FILE_SIZE:
            raise HTTPException(413, detail="File too large.")

        # Store file in MinIO
        storage_info = document_storage.store_document(
            file_data=content,
            filename=file.filename or "unknown",
            knowledge_name=name,
            content_type=file.content_type or "application/octet-stream",
            metadata=metadata,
        )

        # Add storage info to metadata
        metadata.update(
            {
                "storage_path": storage_info["storage_path"],
                "storage_time": storage_info["storage_time"],
            }
        )

        with tempfile.NamedTemporaryFile(
            delete=False, suffix=os.path.splitext(file.filename or "")[1]
        ) as tmp:
            tmp.write(content)
            temp_file = tmp.name

        # Get pipeline vá»›i collection name cá»¥ thá»ƒ
        pipeline = get_rag_pipeline(name)

        # Update chunk config náº¿u khÃ¡c default
        if chunk_size != 1000 or chunk_overlap != 200:
            config = RAGPipelineConfig(
                chunking_config=ChunkingConfig(
                    chunk_size=chunk_size, chunk_overlap=chunk_overlap
                ),
                embedding_config=EmbeddingConfig(),
                vector_store_config=VectorStoreConfig(collection_name=name),
            )
            global rag_pipeline
            rag_pipeline = RAGPipeline(config)
            pipeline = rag_pipeline

        # Add file info vÃ o metadata
        metadata.update(
            {
                "uploaded_filename": file.filename,
                "upload_time": datetime.now().isoformat(),
                "file_size_bytes": size,
                "knowledge_base": name,
            }
        )

        doc_ids = pipeline.process_and_store(temp_file, metadata)
        stats = pipeline.get_stats()
        processing_time = round(time.time() - start_time, 2)

        logger.info(
            f"Uploaded {file.filename} to KB {name}: {len(doc_ids)} vectors in {processing_time}s"
        )

        return FileUploadResponse(
            success=True,
            message=f"Processed {file.filename} -> {len(doc_ids)} vectors",
            file_info=FileInfoModel(**format_file_info(file, size, storage_info)),
            document_ids=doc_ids,
            statistics=stats,
            processing_time=processing_time,
        )

    finally:
        if temp_file and os.path.exists(temp_file):
            os.unlink(temp_file)


@router.get(
    "/knowledge-bases/{name}/stats",
    response_model=Dict[str, Any],
    summary="ðŸ“Š Knowledge Base Stats",
    description="Láº¥y thá»‘ng kÃª cá»§a knowledge base.",
)
async def get_knowledge_base_stats(name: str):
    """
    Láº¥y thá»‘ng kÃª cá»§a knowledge base.

    - **name**: TÃªn cá»§a knowledge base
    """
    try:
        pipeline = get_rag_pipeline(name)
        stats = pipeline.get_stats()
        info = pipeline.vector_store.get_collection_info()

        return {
            "success": True,
            "name": name,
            "stats": stats,
            "collection_info": info,
            "time": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"Error getting KB stats: {e}")
        raise HTTPException(
            500, detail=f"Lá»—i khi láº¥y thá»‘ng kÃª knowledge base: {str(e)}"
        )
