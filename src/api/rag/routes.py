"""
RAG API routes cho knowledge base management v√† document processing
"""

import os
import tempfile
import time
from datetime import datetime
from typing import Dict, Any, List, Optional, Union

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query, status
from fastapi.responses import JSONResponse

from features.rag.rag_pipeline import RAGPipeline, RAGPipelineConfig
from features.rag.chunking import ChunkingConfig
from features.rag.embedding import EmbeddingConfig
from features.rag.vector_store import VectorStoreConfig, VectorStore
from features.rag.storage import document_storage
from core.logging_config import get_logger
from .models import (
    KnowledgeBaseCreate,
    KnowledgeBaseResponse,
    KnowledgeBaseList,
    FileUploadResponse,
    FileInfoModel,
)

router = APIRouter(tags=["RAG Knowledge Base"])
logger = get_logger(__name__)

SUPPORTED_EXTENSIONS = {".pdf", ".docx", ".txt", ".html", ".htm", ".csv", ".md"}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB

# Singleton pipeline
rag_pipeline: RAGPipeline | None = None


def get_rag_pipeline(collection_name: str) -> RAGPipeline:
    """Get RAG pipeline instance v·ªõi collection name c·ª• th·ªÉ."""
    global rag_pipeline
    if not rag_pipeline:
        config = RAGPipelineConfig(
            chunking_config=ChunkingConfig(),
            embedding_config=EmbeddingConfig(),
            vector_store_config=VectorStoreConfig(collection_name=collection_name),
        )
        rag_pipeline = RAGPipeline(config)
    else:
        # Update collection name n·∫øu kh√°c
        if rag_pipeline.vector_store.config.collection_name != collection_name:
            rag_pipeline.vector_store.config.collection_name = collection_name
    return rag_pipeline


def validate_file(file: UploadFile) -> tuple[bool, str]:
    """Validate file type v√† size"""
    if not file.filename:
        return False, "Filename is required"

    ext = os.path.splitext(file.filename.lower())[1]
    if ext not in SUPPORTED_EXTENSIONS:
        return (
            False,
            f"Unsupported file type. Supported: {', '.join(SUPPORTED_EXTENSIONS)}",
        )

    return True, "Valid"


def format_file_info(
    file: UploadFile, size: int, storage_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Format file info cho response"""
    info = {
        "filename": file.filename,
        "file_size": size,
        "file_extension": (
            os.path.splitext(file.filename.lower())[1] if file.filename else ""
        ),
        "content_type": file.content_type or "application/octet-stream",
        "upload_time": datetime.now().isoformat(),
    }

    if storage_info:
        info.update(
            {
                "storage_path": storage_info["storage_path"],
                "storage_time": storage_info["storage_time"],
            }
        )

    return info


@router.post(
    "/knowledge-bases",
    response_model=KnowledgeBaseResponse,
    summary="üìö T·∫°o knowledge base m·ªõi",
    description="T·∫°o knowledge base m·ªõi trong vector store. M·ªói knowledge base l√† m·ªôt collection ri√™ng bi·ªát.",
)
async def create_knowledge_base(kb_data: KnowledgeBaseCreate):
    """
    T·∫°o knowledge base m·ªõi trong vector store.

    - **name**: T√™n c·ªßa knowledge base, s·∫Ω ƒë∆∞·ª£c d√πng l√†m collection name
    - **description**: M√¥ t·∫£ v·ªÅ knowledge base (optional)
    - **metadata**: Metadata b·ªï sung (optional)
    """
    try:
        # Kh·ªüi t·∫°o VectorStore v·ªõi collection name m·ªõi
        config = VectorStoreConfig(collection_name=kb_data.name)
        vector_store = VectorStore(config=config)
        success = vector_store.create_collection(force_recreate=True)

        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Kh√¥ng th·ªÉ t·∫°o collection trong vector store",
            )

        info = vector_store.get_collection_info()

        # ƒê·∫£m b·∫£o lu√¥n c√≥ created_at
        created_at = info.get("created_at")
        if not created_at:
            created_at = datetime.now().isoformat()

        return KnowledgeBaseResponse(
            name=kb_data.name,
            description=kb_data.description,
            metadata=kb_data.metadata,
            collection_info=info,
            created_at=created_at,
        )

    except Exception as e:
        logger.error(f"Error creating KB: {e}")
        raise HTTPException(500, detail=f"L·ªói khi t·∫°o knowledge base: {str(e)}")


@router.get(
    "/knowledge-bases",
    response_model=KnowledgeBaseList,
    summary="üìö L·∫•y danh s√°ch knowledge bases",
    description="L·∫•y danh s√°ch t·∫•t c·∫£ knowledge bases hi·ªán c√≥.",
)
async def list_knowledge_bases():
    """
    L·∫•y danh s√°ch t·∫•t c·∫£ knowledge bases.
    """
    try:
        # Kh·ªüi t·∫°o VectorStore kh√¥ng c·∫ßn embeddings v√¨ ch·ªâ d√πng ƒë·ªÉ qu·∫£n l√Ω collections
        vector_store = VectorStore()
        collections = vector_store.list_collections()

        kbs = []
        for collection in collections:
            # C·∫≠p nh·∫≠t collection name v√† l·∫•y th√¥ng tin
            vector_store.config.collection_name = collection.name
            info = vector_store.get_collection_info()

            # ƒê·∫£m b·∫£o lu√¥n c√≥ created_at
            created_at = info.get("created_at")
            if not created_at:
                created_at = datetime.now().isoformat()

            kbs.append(
                KnowledgeBaseResponse(
                    name=collection.name,
                    description=None,  # Collection info kh√¥ng c√≥ description
                    metadata=None,  # Collection info kh√¥ng c√≥ metadata
                    collection_info=info,
                    created_at=created_at,
                )
            )

        return KnowledgeBaseList(
            knowledge_bases=kbs,
            total=len(kbs),
        )

    except Exception as e:
        logger.error(f"Error listing KBs: {e}")
        raise HTTPException(
            500, detail=f"L·ªói khi l·∫•y danh s√°ch knowledge bases: {str(e)}"
        )


@router.delete(
    "/knowledge-bases/{name}",
    response_model=Dict[str, Any],
    summary="üóëÔ∏è X√≥a knowledge base",
    description="X√≥a knowledge base v√† t·∫•t c·∫£ documents trong ƒë√≥.",
)
async def delete_knowledge_base(name: str):
    """
    X√≥a knowledge base.

    - **name**: T√™n c·ªßa knowledge base c·∫ßn x√≥a
    """
    try:
        # Kh·ªüi t·∫°o VectorStore v·ªõi collection name c·∫ßn x√≥a
        config = VectorStoreConfig(collection_name=name)
        vector_store = VectorStore(config=config)
        success = vector_store.delete_collection()

        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Kh√¥ng th·ªÉ x√≥a knowledge base {name}",
            )

        return {
            "success": True,
            "message": f"ƒê√£ x√≥a knowledge base {name}",
            "time": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"Error deleting KB: {e}")
        raise HTTPException(500, detail=f"L·ªói khi x√≥a knowledge base: {str(e)}")


@router.post(
    "/knowledge-bases/{name}/documents",
    response_model=FileUploadResponse,
    summary="üìÑ Upload document v√†o knowledge base",
    description="Upload v√† process document v√†o knowledge base c·ª• th·ªÉ.",
)
async def upload_document(
    name: str,
    file: UploadFile = File(...),
    chunk_size: int = Form(1000),
    chunk_overlap: int = Form(200),
    metadata: Dict[str, Any] = Form({}),
):
    """
    Upload v√† process document v√†o knowledge base.

    - **name**: T√™n c·ªßa knowledge base
    - **file**: File c·∫ßn upload
    - **chunk_size**: K√≠ch th∆∞·ªõc m·ªói chunk (default: 1000)
    - **chunk_overlap**: ƒê·ªô overlap gi·ªØa c√°c chunks (default: 200)
    - **metadata**: Metadata b·ªï sung cho document
    """
    start_time = time.time()
    temp_file = None

    try:
        valid, msg = validate_file(file)
        if not valid:
            raise HTTPException(400, detail=msg)

        content = await file.read()
        size = len(content)
        if size > MAX_FILE_SIZE:
            raise HTTPException(413, detail="File too large.")

        # Store file in MinIO
        storage_info = document_storage.store_document(
            file_data=content,
            filename=file.filename or "unknown",
            knowledge_name=name,
            content_type=file.content_type or "application/octet-stream",
            metadata=metadata,
        )

        # Add storage info to metadata
        metadata.update(
            {
                "storage_path": storage_info["storage_path"],
                "storage_time": storage_info["storage_time"],
            }
        )

        with tempfile.NamedTemporaryFile(
            delete=False, suffix=os.path.splitext(file.filename or "")[1]
        ) as tmp:
            tmp.write(content)
            temp_file = tmp.name

        # Get pipeline v·ªõi collection name c·ª• th·ªÉ
        pipeline = get_rag_pipeline(name)

        # Update chunk config n·∫øu kh√°c default
        if chunk_size != 1000 or chunk_overlap != 200:
            config = RAGPipelineConfig(
                chunking_config=ChunkingConfig(
                    chunk_size=chunk_size, chunk_overlap=chunk_overlap
                ),
                embedding_config=EmbeddingConfig(),
                vector_store_config=VectorStoreConfig(collection_name=name),
            )
            global rag_pipeline
            rag_pipeline = RAGPipeline(config)
            pipeline = rag_pipeline

        # Add file info v√†o metadata
        metadata.update(
            {
                "uploaded_filename": file.filename,
                "upload_time": datetime.now().isoformat(),
                "file_size_bytes": size,
                "knowledge_base": name,
            }
        )

        doc_ids = pipeline.process_and_store(temp_file, metadata)
        stats = pipeline.get_stats()
        processing_time = round(time.time() - start_time, 2)

        logger.info(
            f"Uploaded {file.filename} to KB {name}: {len(doc_ids)} vectors in {processing_time}s"
        )

        return FileUploadResponse(
            success=True,
            message=f"Processed {file.filename} -> {len(doc_ids)} vectors",
            file_info=FileInfoModel(**format_file_info(file, size, storage_info)),
            document_ids=doc_ids,
            statistics=stats,
            processing_time=processing_time,
        )

    finally:
        if temp_file and os.path.exists(temp_file):
            os.unlink(temp_file)


@router.get(
    "/knowledge-bases/{name}/stats",
    response_model=Dict[str, Any],
    summary="üìä Knowledge Base Stats",
    description="L·∫•y th·ªëng k√™ c·ªßa knowledge base.",
)
async def get_knowledge_base_stats(name: str):
    """
    L·∫•y th·ªëng k√™ c·ªßa knowledge base.

    - **name**: T√™n c·ªßa knowledge base
    """
    try:
        pipeline = get_rag_pipeline(name)
        stats = pipeline.get_stats()
        info = pipeline.vector_store.get_collection_info()

        return {
            "success": True,
            "name": name,
            "stats": stats,
            "collection_info": info,
            "time": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"Error getting KB stats: {e}")
        raise HTTPException(
            500, detail=f"L·ªói khi l·∫•y th·ªëng k√™ knowledge base: {str(e)}"
        )
