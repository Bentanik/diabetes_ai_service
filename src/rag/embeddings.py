"""
Dá»‹ch vá»¥ embedding sá»­ dá»¥ng HuggingFace models.
Tá»‘i Æ°u hÃ³a cho tiáº¿ng Viá»‡t vÃ  há»— trá»£ nhiá»u models khÃ¡c nhau.
"""

import os
from typing import List, Optional
from langchain_community.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings
from core.logging_config import get_logger
import torch

logger = get_logger(__name__)


def auto_detect_device() -> str:
    """
    Tá»± Ä‘á»™ng phÃ¡t hiá»‡n thiáº¿t bá»‹ tá»‘t nháº¥t cÃ³ sáºµn.

    Returns:
        Device string: "cuda" náº¿u cÃ³ GPU, "cpu" náº¿u khÃ´ng
    """
    if torch.cuda.is_available():
        return "cuda"
    else:
        # Kiá»ƒm tra sá»‘ lÃµi CPU Ä‘á»ƒ optimize
        cpu_count = os.cpu_count() or 4
        logger.info(f"GPU khÃ´ng available, sá»­ dá»¥ng CPU vá»›i {cpu_count} cores")
        return "cpu"


class Embeddings:
    """
    Dá»‹ch vá»¥ embedding HuggingFace Ä‘Æ°á»£c tá»‘i Æ°u cho tiáº¿ng Viá»‡t.
    Sá»­ dá»¥ng sentence transformers vá»›i há»— trá»£ GPU tá»± Ä‘á»™ng.
    """

    def __init__(
        self,
        model_name: str = "intfloat/multilingual-e5-base",
        device: str = "auto",
        normalize_embeddings: bool = True,
    ):
        """
        Khá»Ÿi táº¡o dá»‹ch vá»¥ embedding.

        Args:
            model_name: TÃªn model HuggingFace
            device: Thiáº¿t bá»‹ cháº¡y ("auto", "cpu", "cuda")
            normalize_embeddings: Chuáº©n hÃ³a vector embeddings
        """
        self.model_name = model_name

        # Auto-detect device náº¿u Ä‘Æ°á»£c yÃªu cáº§u
        if device == "auto":
            device = auto_detect_device()

        self.device = device
        self.normalize_embeddings = normalize_embeddings

        # Cáº¥u hÃ¬nh tá»‘i Æ°u cho CPU náº¿u cáº§n
        model_kwargs = {"device": device}
        encode_kwargs = {"normalize_embeddings": normalize_embeddings}

        # Tá»‘i Æ°u cho CPU
        if device == "cpu":
            # TÄƒng sá»‘ threads cho CPU processing
            torch.set_num_threads(torch.get_num_threads())
            logger.info(f"Tá»‘i Æ°u CPU: sá»­ dá»¥ng {torch.get_num_threads()} threads")

            # HuggingFaceEmbeddings khÃ´ng support custom batch_size trong encode_kwargs
            # Chá»‰ giá»¯ normalize_embeddings

        # Khá»Ÿi táº¡o HuggingFace embeddings
        self.embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs,
        )

        logger.info(f"ÄÃ£ khá»Ÿi táº¡o Vietnamese embedding service")
        logger.info(f"Model: {model_name}")
        logger.info(f"Device: {device}")
        logger.info(f"Normalize: {normalize_embeddings}")

        if device == "cpu":
            logger.warning("âš ï¸  ÄANG CHáº Y TRÃŠN CPU - Performance sáº½ cháº­m hÆ¡n GPU")
            logger.info("ðŸ’¡ Äá»ƒ tÄƒng tá»‘c: cÃ i PyTorch vá»›i CUDA hoáº·c dÃ¹ng model nhá» hÆ¡n")

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        Táº¡o embeddings cho danh sÃ¡ch vÄƒn báº£n.

        Args:
            texts: Danh sÃ¡ch vÄƒn báº£n cáº§n embedding

        Returns:
            Danh sÃ¡ch vectors embedding
        """
        try:
            embeddings = self.embeddings.embed_documents(texts)
            logger.debug(f"ÄÃ£ táº¡o embeddings cho {len(texts)} vÄƒn báº£n")
            return embeddings
        except Exception as e:
            logger.error(f"Lá»—i táº¡o embeddings cho documents: {e}")
            raise

    def embed_query(self, text: str) -> List[float]:
        """
        Táº¡o embedding cho cÃ¢u há»i.

        Args:
            text: CÃ¢u há»i cáº§n embedding

        Returns:
            Vector embedding cá»§a cÃ¢u há»i
        """
        try:
            embedding = self.embeddings.embed_query(text)
            logger.debug(f"ÄÃ£ táº¡o embedding cho query: {text[:50]}...")
            return embedding
        except Exception as e:
            logger.error(f"Lá»—i táº¡o embedding cho query: {e}")
            raise

    def get_info(self) -> dict:
        """Láº¥y thÃ´ng tin vá» service embedding."""
        return {
            "provider": "huggingface",
            "model_name": self.model_name,
            "device": self.device,
            "normalize_embeddings": self.normalize_embeddings,
            "supports_vietnamese": True,
            "model_type": "sentence_transformer",
        }


class MultiEmbeddingService:
    """
    Dá»‹ch vá»¥ embedding há»— trá»£ nhiá»u provider.
    Cho phÃ©p chuyá»ƒn Ä‘á»•i giá»¯a HuggingFace vÃ  OpenAI.
    """

    def __init__(
        self,
        provider: str = "huggingface",
        model_name: str = "intfloat/multilingual-e5-base",
        api_key: Optional[str] = None,
        device: str = "auto",
    ):
        """
        Khá»Ÿi táº¡o multi embedding service.

        Args:
            provider: Loáº¡i provider (huggingface hoáº·c openai)
            model_name: TÃªn model
            api_key: API key cho OpenAI (náº¿u cáº§n)
            device: Thiáº¿t bá»‹ cháº¡y
        """
        self.provider = provider
        self.model_name = model_name
        self.device = device

        if provider == "huggingface":
            self.embeddings = Embeddings(model_name=model_name, device=device)
        elif provider == "openai":
            if not api_key:
                api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OpenAI API key khÃ´ng Ä‘Æ°á»£c cung cáº¥p")

            self.embeddings = OpenAIEmbeddings(
                api_key=api_key, model=model_name or "text-embedding-3-small"
            )
        else:
            raise ValueError(f"Provider khÃ´ng Ä‘Æ°á»£c há»— trá»£: {provider}")

        logger.info(f"ÄÃ£ khá»Ÿi táº¡o multi embedding service vá»›i provider: {provider}")

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Táº¡o embeddings cho danh sÃ¡ch vÄƒn báº£n."""
        return self.embeddings.embed_documents(texts)

    def embed_query(self, text: str) -> List[float]:
        """Táº¡o embedding cho cÃ¢u há»i."""
        return self.embeddings.embed_query(text)

    def get_info(self) -> dict:
        """Láº¥y thÃ´ng tin vá» service."""
        if isinstance(self.embeddings, Embeddings):
            return self.embeddings.get_info()
        else:
            return {
                "provider": self.provider,
                "model_name": self.model_name,
                "device": self.device if self.provider == "huggingface" else "api",
                "supports_vietnamese": self.provider == "huggingface",
            }


# Cáº¥u hÃ¬nh model embedding cá»‘ Ä‘á»‹nh cho tiáº¿ng Viá»‡t
MODEL_DEFAULT_EMBEDDING = "intfloat/multilingual-e5-base"

# KhÃ´ng cáº§n configs phá»©c táº¡p - chá»‰ dÃ¹ng E5-base cho má»i trÆ°á»ng há»£p


def get_embedding_service(
    provider: str = "huggingface",
    model_name: Optional[str] = None,
    api_key: Optional[str] = None,
    device: str = "auto",
) -> MultiEmbeddingService:
    """
    Factory function Ä‘á»ƒ táº¡o embedding service.

    Args:
        provider: Loáº¡i provider (huggingface hoáº·c openai)
        model_name: TÃªn model (máº·c Ä‘á»‹nh: intfloat/multilingual-e5-base)
        api_key: API key cho OpenAI
        device: Thiáº¿t bá»‹ cháº¡y ("auto", "cpu", "cuda")

    Returns:
        Instance cá»§a MultiEmbeddingService
    """
    # Auto-detect device
    if device == "auto":
        device = auto_detect_device()

    # Sá»­ dá»¥ng model cá»‘ Ä‘á»‹nh E5-base cho táº¥t cáº£ trÆ°á»ng há»£p
    if not model_name:
        if provider == "huggingface":
            model_name = MODEL_DEFAULT_EMBEDDING
        elif provider == "openai":
            model_name = "text-embedding-3-small"
        else:
            model_name = MODEL_DEFAULT_EMBEDDING

    # Ensure model_name is not None
    final_model_name = model_name or "intfloat/multilingual-e5-base"

    return MultiEmbeddingService(
        provider=provider, model_name=final_model_name, api_key=api_key, device=device
    )


def get_vietnamese_embedding_service(
    model_name: str = "intfloat/multilingual-e5-base", device: str = "cpu"
) -> Embeddings:
    """
    Táº¡o embedding service tá»‘i Æ°u cho tiáº¿ng Viá»‡t.

    Args:
        model_name: TÃªn model HuggingFace
        device: Thiáº¿t bá»‹ cháº¡y

    Returns:
        Embeddings instance
    """
    return Embeddings(model_name=model_name, device=device)
