# simple_rag.py
from core.llm.gemini.client import GeminiClient
from typing import List


# def rag_chat(
#     message: str,
#     retrieved_data: List[str],
#     history: List = None,
#     document_name: str = "tÃ i liá»‡u",
# ) -> str:
#     client = GeminiClient()

#     if not retrieved_data:
#         return f"Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» '{message}' trong {document_name} hiá»‡n cÃ³."

#     context = "=== Dá»® LIá»†U LIÃŠN QUAN ===\n"
#     for i, data in enumerate(retrieved_data, 1):
#         context += f"{i}. {data}\n"
#     context += "========================"

#     # ThÃªm relevant history
#     if history:
#         relevant_history = _get_relevant_history(message, history, max_turns=2)
#         if relevant_history:
#             context += "\n\n=== Bá»I Cáº¢NH Há»˜I THOáº I ===\n"
#             for turn in relevant_history:
#                 context += f"User: {turn['user']}\nAI: {turn['ai']}\n"
#             context += "========================"

#     system_prompt = f"""
#     Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn nghiá»‡p. 
    
#     NHIá»†M Vá»¤:
#     1. Sá»­ dá»¥ng Dá»® LIá»†U LIÃŠN QUAN lÃ m nguá»“n thÃ´ng tin chÃ­nh
#     2. Tham kháº£o Bá»I Cáº¢NH Há»˜I THOáº I Ä‘á»ƒ hiá»ƒu cÃ¢u há»i follow-up
#     3. Tráº£ lá»i chÃ­nh xÃ¡c, khÃ´ng bá»‹a Ä‘áº·t
    
#     VÃ Dá»¤ FOLLOW-UP:
#     - "CÃ²n vá» váº¥n Ä‘á» khÃ¡c thÃ¬ sao?" â†’ Cáº§n hiá»ƒu "váº¥n Ä‘á» khÃ¡c" lÃ  gÃ¬ tá»« context
#     - "Tháº¿ cÃ²n cÃ¡i Ä‘Ã³?" â†’ "cÃ¡i Ä‘Ã³" refer Ä‘áº¿n gÃ¬ trong lá»‹ch sá»­
#     """

#     response = client.prompt(
#         message=message, system_prompt=system_prompt, context=context
#     )

#     return response


# def _expand_query_with_history(message: str, history: List) -> str:
#     """Má»Ÿ rá»™ng query dá»±a trÃªn history Ä‘á»ƒ retrieve tá»‘t hÆ¡n"""
#     if not history:
#         return message

#     # Láº¥y 2 turn gáº§n nháº¥t
#     recent_context = []
#     for turn in history[-2:]:
#         recent_context.append(f"User: {turn.get('user', '')}")
#         recent_context.append(f"AI: {turn.get('ai', '')}")

#     expanded = f"{' '.join(recent_context)} {message}"
#     return expanded


# def _get_relevant_history(message: str, history: List, max_turns: int = 2) -> List:
#     """Láº¥y history cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i hiá»‡n táº¡i"""
#     # Simple approach: láº¥y nhá»¯ng turn gáº§n nháº¥t
#     return history[-max_turns:] if history else []


# # Sá»­ dá»¥ng
# def main():
#     # Simulate conversation
#     history = []

#     # Turn 1
#     print("=== Turn 1 ===")
#     retrieved_data1 = ["Python Ä‘Æ°á»£c táº¡o bá»Ÿi Guido van Rossum nÄƒm 1991"]
#     response1 = rag_chat("Python do ai táº¡o ra?", retrieved_data1, history)
#     print("ğŸ¤–:", response1)

#     # Update history
#     history.append({"user": "Python do ai táº¡o ra?", "ai": response1})

#     # Turn 2 - Follow-up question
#     print("\n=== Turn 2 ===")
#     retrieved_data2 = ["Guido van Rossum sinh nÄƒm 1956 táº¡i HÃ  Lan"]
#     response2 = rag_chat("Ã”ng áº¥y sinh nÄƒm nÃ o?", retrieved_data2, history)
#     print("ğŸ¤–:", response2)

#     # Update history
#     history.append({"user": "Ã”ng áº¥y sinh nÄƒm nÃ o?", "ai": response2})

#     # Turn 3 - No relevant data
#     print("\n=== Turn 3 ===")
#     response3 = rag_chat("Ã”ng áº¥y cÃ³ con khÃ´ng?", [], history)
#     print("ğŸ¤–:", response3)


# if __name__ == "__main__":
#     main()


if __name__ == "__main__":
    main()
